{
  
    
        "post0": {
            "title": "Israel excess mortality 2020 תמותה עודפת בישראל",
            "content": "This post in continues my previous one that examined excess mortality in Israel during the summer of 2020 based on CBS (למ&quot;ס) mortality data. So for more background feel free to read that one (assuming you understand Hebrew :)). ` Cuurent work extends the previous one in the following: . Using an updated mortality statistics file is used (published on October 14). | Examining predicting yearly expected mortality rate and using it instead of average of last 5 years (as discussed in this article). | CBS Like analysis . At first we&#39;ll repeat the CBS analysis using the updated mortality data file. Let&#39;s download it and take a look at what it contains. . #collapse import urllib import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline MORTALITY_FILE_URL = &#39;https://www.cbs.gov.il/he/publications/LochutTlushim/2020/%D7%A4%D7%98%D7%99%D7%A8%D7%95%D7%AA-2000-2020-%D7%9C%D7%A4%D7%99-%D7%A9%D7%91%D7%95%D7%A2.xlsx&#39; MORTALITY_FILE_LOCATION = &quot;/home/adiell/data/israel_moratality_stats-oct14.xslx&quot; . . #collapse ## Run this to get the data from CBS website #urllib.request.urlretrieve(MORTALITY_FILE_URL, MORTALITY_FILE_LOCATION) . . #collapse AGE_GROUPS = [&quot;0-19&quot;, &quot;20-29&quot;, &quot;30-39&quot;, &quot;40-49&quot;, &quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;,&quot;80+&quot;] COLUMNS_NAMES = [&quot;Week&quot;, &quot;Date&quot;, &quot;Total&quot;, &quot;Males&quot;, &quot;Females&quot;, &quot;Total - Jews&quot;, &quot;Males - Jews&quot;, &quot;Females - Jews&quot;, &quot;Total - Arabs&quot;, &quot;Males - Arabs&quot;, &quot;Females - Arabs&quot;, &quot;Total - 70+&quot;, &quot;Arabs - 70+&quot;, &quot;Jews - 70+&quot;, &quot;Males - 70+&quot;, &quot;Males - Arabs - 70+&quot;, &quot;Males - Jews - 70+&quot;, &quot;Females - 70+&quot;, &quot;Females - Arabs - 70+&quot;, &quot;Females - Jews - 70+&quot; ] + [&quot;Males - &quot; + age for age in AGE_GROUPS] + [&quot;Females - &quot; + age for age in AGE_GROUPS] . . #collapse def read_sheet(year): df = pd.read_excel(MORTALITY_FILE_LOCATION, sheet_name = str(year), skiprows=12) df.columns = COLUMNS_NAMES df[&#39;year&#39;] = year df[&#39;month&#39;] = df[&#39;Date&#39;].apply(lambda x: x.month) return df . . #collapse mortality_raw_data = pd.concat([read_sheet(year) for year in range(2000, 2021)]) mortality_raw_data = mortality_raw_data.dropna(subset=[&quot;Total&quot;]) ## Future dates have NA . . Let&#39;s look at the raw total mortaility data: . #collapse mortality_raw_data.tail(1) . . Week Date Total Males Females Total - Jews Males - Jews Females - Jews Total - Arabs Males - Arabs ... Females - 30-39 Females - 40-49 Females - 50-59 Females - 60-69 Females - 70-79 Females - 80+ year month population Norm. Total . 1078 36 | 2020-08-31 | 809.0 | 436.0 | 373.0 | 694.0 | 362.0 | 332.0 | 115.0 | 74.0 | ... | 5.0 | 5.0 | 14.0 | 35.0 | 70.0 | 240.0 | 2020 | 8 | 9190.0 | 0.08803 | . 1 rows × 40 columns . Data is updated only until the end of August (compared to mid-August in the previous post). It contains metrics for various demographic groups. I&#39;ll focus here on total mortality and not on a specific group. . In their report the CBS normalizes the mortality by the population size and compares 2020 values to the average of 2015-2019. We&#39;ll do the same. The size of the population in taken from Wikipedia (see previous post for more details), similar to CBS analysis. The population is given is 1000s of people. In addition, confidence bounds are computed using the standard deviation. . #collapse population = pd.DataFrame( { &#39;year&#39; : range(2000, 2021), &#39;population&#39;: [6369, 6508, 6631, 6748, 6869, 6991, 7116, 7244, 7337, 7552, 7695, 7837, 7984, 8134, 8297, 8463, 8628, (8628*8972)**0.5, 8972, 9021, 9190] } ) population . . year population . 0 2000 | 6369.00000 | . 1 2001 | 6508.00000 | . 2 2002 | 6631.00000 | . 3 2003 | 6748.00000 | . 4 2004 | 6869.00000 | . 5 2005 | 6991.00000 | . 6 2006 | 7116.00000 | . 7 2007 | 7244.00000 | . 8 2008 | 7337.00000 | . 9 2009 | 7552.00000 | . 10 2010 | 7695.00000 | . 11 2011 | 7837.00000 | . 12 2012 | 7984.00000 | . 13 2013 | 8134.00000 | . 14 2014 | 8297.00000 | . 15 2015 | 8463.00000 | . 16 2016 | 8628.00000 | . 17 2017 | 8798.31893 | . 18 2018 | 8972.00000 | . 19 2019 | 9021.00000 | . 20 2020 | 9190.00000 | . #collapse column_of_interest = &quot;Total&quot; mortality_raw_data = mortality_raw_data.merge(population) normed_columns_of_interest = &#39;Norm. &#39; + column_of_interest mortality_raw_data[normed_columns_of_interest] = mortality_raw_data[column_of_interest]/ mortality_raw_data[&#39;population&#39;] . . #collapse class CBSModel(): def __init__(self, metric, norm_factor = population[&#39;population&#39;].values[-1], debias_factor = 1): self._metric = metric self._norm_factor = norm_factor self._debias_factor = debias_factor def fit(self, df): mean = self._norm_factor * df .query(&#39;2015 &lt;= year &lt;= 2019&#39;) .groupby(&#39;Week&#39;)[self._metric].mean() mean = mean.rolling(3, center=True, min_periods=1).mean() std = self._norm_factor * df .query(&#39;2015 &lt;= year &lt;= 2019&#39;) .groupby(&#39;Week&#39;)[self._metric].std() std = std.rolling(3, center=True, min_periods=1).mean() self._model = pd.concat([mean, std], axis = 1) self._model.columns = [&#39;mean&#39;, &#39;std&#39;] def predict(self, df, conf_level = 1.96): return df.merge(self._model, left_on=&#39;Week&#39;, right_index=True). assign( actual_mortality = lambda x: x[self._metric] * self._norm_factor, predicted_mortality = lambda x: self._debias_factor*x[&#39;mean&#39;], upper_bound = lambda x: self._debias_factor*x[&#39;mean&#39;] + (conf_level * x[&#39;std&#39;]), lower_bound = lambda x: self._debias_factor*x[&#39;mean&#39;] - (conf_level * x[&#39;std&#39;]), )[[&#39;Date&#39;, &#39;year&#39;, &#39;Week&#39;, &#39;month&#39;, &#39;actual_mortality&#39;, &#39;predicted_mortality&#39; ,&#39;lower_bound&#39;, &#39;upper_bound&#39;]] . . #collapse cbs_model = CBSModel(normed_columns_of_interest) pre_covid_data = mortality_raw_data.query(&#39;Date &lt;= &quot;2020-03-01&quot;&#39;) cbs_model.fit(pre_covid_data) cbs_result = cbs_model.predict(mortality_raw_data.query(&#39;Date &gt;= &quot;2020-01-01&quot;&#39;)) . . #collapse def plot_mortality_predition(result): fig = plt.figure(figsize = (12,6)) plt.plot(result[&#39;Date&#39;], result[&#39;actual_mortality&#39;],&#39;r&#39;, label = &#39;Actual mortality&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;predicted_mortality&#39;],&#39;b&#39;, label = &#39;Predicted mortality&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;upper_bound&#39;],&#39;b--&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;lower_bound&#39;],&#39;b--&#39;) _=plt.legend() plot_mortality_predition(cbs_result) . . Results are very similar to previous ones. The mortaility is above expectation since July. For a couple of weeks in August it is also above the confidence bounds. Mortality for the last datapoint is rather low which hints the data is partial for this period (as also indicated in CBS explanations on the data). Let&#39;s summarise the excess mortality by month. . #collapse cbs_result.assign( excess_mortality = lambda x: x.actual_mortality - x.predicted_mortality, excess_mortality_percent = lambda x: (x.actual_mortality - x.predicted_mortality)/x.predicted_mortality ).groupby(&#39;month&#39;) .agg({&#39;excess_mortality&#39;: &#39;sum&#39;, &#39;excess_mortality_percent&#39;: &#39;mean&#39;}) . . excess_mortality excess_mortality_percent . month . 1 -274.799115 | -0.062750 | . 2 -369.688408 | -0.088203 | . 3 102.541240 | 0.023642 | . 4 35.815022 | 0.010170 | . 5 146.766899 | 0.043999 | . 6 -69.662591 | -0.017425 | . 7 180.894336 | 0.055749 | . 8 303.624305 | 0.074873 | . So excess mortality in percent on August is about 7.5% (compared to 6.8%) in previous analysis. . Is the normalization by population appropriate? . In this article it is argued that the mortality rate normalized by the population size is trending down, and therefore comparing 2020 numbers vs average of 2015-2019 leads to bias and in the results, and actual excess mortality should be higher. It is suggested to calculate the expected mortaloity rate by linear regression on the year 2010-2019 and use it to debias the results. Here we examine this too. Let&#39;s calculate the yearly normalized mortality rate. . #collapse yearly_mortality = mortality_raw_data.groupby(&#39;year&#39;).agg( mortality = pd.NamedAgg(column_of_interest, &#39;sum&#39;), population = pd.NamedAgg(&#39;population&#39;, &#39;mean&#39;) ).assign( norm_mortality = lambda x: x.mortality/x.population ).reset_index().query(&#39;year &lt; 2020&#39;) _ = yearly_mortality.plot.scatter(x = &#39;year&#39;, y = &#39;norm_mortality&#39;) . . Indeed the mortality is trending down, however the trends levels off in recent years and the mortality rate looks quite constant and dominated by noise. Not suרe what will be the value of using a more complex model over just taking the average of 2015-2019. Let&#39;s vizualize it using seaborn regplot. . #collapse sns.regplot(x = &#39;year&#39;, y = &#39;norm_mortality&#39;, data = yearly_mortality.query(&#39;year &gt;= 2010&#39;)) . . &lt;AxesSubplot:xlabel=&#39;year&#39;, ylabel=&#39;norm_mortality&#39;&gt; . A very noisy downward sloping trend. Let&#39;s calculate the average mortality rate for 2015-2019: . #collapse yearly_mortality.query(&#39;year &gt;= 2015&#39;)[&#39;norm_mortality&#39;].mean() . . 5.093307399710677 . And using linear regression: . #collapse from sklearn.linear_model import LinearRegression X = yearly_mortality.query(&#39;year &gt;= 2010&#39;)[&#39;year&#39;].values.reshape(-1,1) y = yearly_mortality.query(&#39;year &gt;= 2010&#39;)[&#39;norm_mortality&#39;] reg = LinearRegression() reg.fit(X,y) reg.predict([[2020]]) . . array([5.02952005]) . So indeed if we believe the regression result, the analysis is bias by a factor of around 5.09/5.03 = 1.012 or around 1.2%. . #collapse cbs_model2 = CBSModel(normed_columns_of_interest, debias_factor=5.03/5.09) pre_covid_data2 = mortality_raw_data.query(&#39;Date &lt;= &quot;2020-03-01&quot;&#39;) cbs_model2.fit(pre_covid_data2) cbs_result2 = cbs_model2.predict(mortality_raw_data.query(&#39;Date &gt;= &quot;2020-01-01&quot;&#39;)) plot_mortality_predition(cbs_result2) . . A small difference is visible. What about the aggragate metrics? . #collapse cbs_result2.assign( excess_mortality = lambda x: x.actual_mortality - x.predicted_mortality, excess_mortality_percent = lambda x: (x.actual_mortality - x.predicted_mortality)/x.predicted_mortality ).groupby(&#39;month&#39;) .agg({&#39;excess_mortality&#39;: &#39;sum&#39;, &#39;excess_mortality_percent&#39;: &#39;mean&#39;}) . . excess_mortality excess_mortality_percent . month . 1 -223.229773 | -0.051571 | . 2 -320.536875 | -0.077327 | . 3 157.843308 | 0.035853 | . 4 77.039206 | 0.022220 | . 5 186.270629 | 0.056452 | . 6 -22.491716 | -0.005705 | . 7 218.946662 | 0.068343 | . 8 351.345826 | 0.087695 | . Excess mortality is larger by ~1.2% as expected. . That&#39;s it for today. I did not repeat the prophet analysis since I doubt it will be very interesting. Similarly for other time series forecasting method (well, that and the lack of time). .",
            "url": "https://adiell.github.io/fp-blog/covid-19/2020/10/18/Israel_excess_mortality-cont.html",
            "relUrl": "/covid-19/2020/10/18/Israel_excess_mortality-cont.html",
            "date": " • Oct 18, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "תמותה עודפת בישראל בקיץ 2020 (Israel excess mortality summer 2020)",
            "content": "כחלק מהדיון הציבורי על מגפת הקורונה ודרכי ההתמודדות עימה, עלתה הטענה כי מרבית הנפטרים הנכללים בסטטיסטיקת הנפטרים עקב המחלה אינם נפטרים &quot;מקורונה&quot; אלא &quot;עם קורונה&quot;. הם &quot;מתים מהלכים&quot; אשר היו מתים מסיבות אלו ואחרות גם ללא קשר להמצאות נגיף הקורונה בגופם. לטענה זו יש היבטים שונים, מוסריים (האם מותר לדרוס &quot;מתים מהלכים&quot;?), ביולוגיים/רפואיים, סטטיסטיים ועוד. . מטרת פוסט זה להתמקד באספקט צר (אך חשוב!) ולבחון האם קיימת תמותה עודפת בישראל בשנת 2020 ובפרט בחודשי הקיץ של שנה זו, כיוון שהמצאות תמותה עודפת עשויה להצביע על נפטרים &quot;מקורונה&quot; ולא &quot;עם קורונה&quot;. במספר מדינות בעולם הודגמה תמותה עודפת בשנת 2020 (לדוגמא כאן). בישראל הופיע באחרונה בכותרות דו&quot;ח של הלמ&quot;ס בו לא נמצאה עלייה משמעותית בתמותה. דו&quot;ח זה כולל נתונים אך ורק עד ליולי 2020. בחודש זה חלה אמנם עלייה משמעותית בתחלואה ובסטטיסטקת הנפטרים &quot;עם קורונה&quot;, אך עלייה זו המשיכה והתגברה מאז ועד למועד כתיבת שורות אלו (20.9.2020),כך שיש עניין לבחון האם בנתונים החדשים ניתן לראות תמותה עודפת או לא? . לצערי, הנתונים העדכניים ביותר באתר הלמ&quot;ס מגיעים עד לאמצע אוגוסט, כך שהתוספת על דו&quot;ח הלמ&quot;ס הינה קטנה יחסית. בעתיד יהיה ניתן לעדכן את הניתוח עם נתונים חדשים. השתמשתי בקובץ &quot;פטירות של תושבי ישראל, לפי שבוע, מין, קבוצת אוכלוסייה וגיל, 2020&quot; שהורדתי מכאן. ניתן למצוא שם קבצים נוספים ברזולציות אחרות. . מן הראוי להעיר שבעוד ההתסכלות על נתוני תמותה עודפת היא חשובה ביותר, היא אינה חפה מבעיות. בפרט, היא חשופה לתנודות אחרות בתמותה, לדוגמא ירידה התמותה מתאונות דרכים כאן עמ&#39; 11-12, התאבדויות עקב בדידות ומצוקה כלכלית (לא ראיתי נתונים, אך כן נבואות זעם) ועוד. . EDA . #collapse import urllib import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline MORTALITY_FILE_URL = &#39;https://www.cbs.gov.il/he/publications/LochutTlushim/2020/%D7%A4%D7%98%D7%99%D7%A8%D7%95%D7%AA-2000-2020-%D7%9C%D7%A4%D7%99-%D7%A9%D7%91%D7%95%D7%A2.xlsx&#39; MORTALITY_FILE_LOCATION = &quot;/home/adiell/data/israel_moratality_stats.xslx&quot; . . #collapse ## Run this to get the data from CBS website # urllib.request.urlretrieve(FILE_URL, MORTALITY_FILE_LOCATION) . . #collapse AGE_GROUPS = [&quot;0-19&quot;, &quot;20-29&quot;, &quot;30-39&quot;, &quot;40-49&quot;, &quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;,&quot;80+&quot;] COLUMNS_NAMES = [&quot;Week&quot;, &quot;Date&quot;, &quot;Total&quot;, &quot;Males&quot;, &quot;Females&quot;, &quot;Total - Jews&quot;, &quot;Males - Jews&quot;, &quot;Females - Jews&quot;, &quot;Total - Arabs&quot;, &quot;Males - Arabs&quot;, &quot;Females - Arabs&quot;, &quot;Total - 70+&quot;, &quot;Arabs - 70+&quot;, &quot;Jews - 70+&quot;, &quot;Males - 70+&quot;, &quot;Males - Arabs - 70+&quot;, &quot;Males - Jews - 70+&quot;, &quot;Females - 70+&quot;, &quot;Females - Arabs - 70+&quot;, &quot;Females - Jews - 70+&quot; ] + [&quot;Males - &quot; + age for age in AGE_GROUPS] + [&quot;Females - &quot; + age for age in AGE_GROUPS] . . #collapse def read_sheet(year): df = pd.read_excel(MORTALITY_FILE_LOCATION, sheet_name = str(year), skiprows=12) df.columns = COLUMNS_NAMES df[&#39;year&#39;] = year df[&#39;month&#39;] = df[&#39;Date&#39;].apply(lambda x: x.month) return df . . #collapse mortality_raw_data = pd.concat([read_sheet(year) for year in range(2000, 2021)]) mortality_raw_data = mortality_raw_data.dropna(subset=[&quot;Total&quot;]) ## Future dates have NA . . נתמקד בנתוני התמותה הכוללת ולא במגזר או חתך ספציפי. יהיה מעניין לחזור על הניתוח עבור חתכים נוספים. אם נמצא משהו מעניין, זה יכול לעזור להעמקת השסעים בחברה הישראלית. . #collapse column_of_interest = &quot;Total&quot; _ = mortality_raw_data.plot(&quot;Date&quot;, column_of_interest, figsize = (12,6)) . . הנתונים בעלי עונתיות שנתית ומגמת גידול כללית. אפשר לנסות לתקנן את מגמת הגידול אם נחלק בגודל האוכלוסיה (לא אידיאלי כי מה שרלוונטי זו האוכלוסיה המבוגרת יותר, אבל זה מה שיש וקל לעשות :). זה גם מה שהלמ&quot;ס עושים כמדומני. בנוסף גם המידע ברזולוציה זמנית אחרת. מה לעשות). את נתוני גודל האוכלוסיה לקחתי מויקיפדיה (משום מה לא ראיתי נתונים דומים באתר הלמ&quot;ס). משום מה גם אין נתונים על גודל האוכלוסיה ב2017 אז השלמתי על ידי ממוצע גאומטרי של 2016,2018 . #collapse population = pd.DataFrame( { &#39;year&#39; : range(2000, 2021), &#39;population&#39;: [6369, 6508, 6631, 6748, 6869, 6991, 7116, 7244, 7337, 7552, 7695, 7837, 7984, 8134, 8297, 8463, 8628, (8628*8972)**0.5, 8972, 9021, 9190] } ) population . . year population . 0 2000 | 6369.00000 | . 1 2001 | 6508.00000 | . 2 2002 | 6631.00000 | . 3 2003 | 6748.00000 | . 4 2004 | 6869.00000 | . 5 2005 | 6991.00000 | . 6 2006 | 7116.00000 | . 7 2007 | 7244.00000 | . 8 2008 | 7337.00000 | . 9 2009 | 7552.00000 | . 10 2010 | 7695.00000 | . 11 2011 | 7837.00000 | . 12 2012 | 7984.00000 | . 13 2013 | 8134.00000 | . 14 2014 | 8297.00000 | . 15 2015 | 8463.00000 | . 16 2016 | 8628.00000 | . 17 2017 | 8798.31893 | . 18 2018 | 8972.00000 | . 19 2019 | 9021.00000 | . 20 2020 | 9190.00000 | . #collapse mortality_raw_data = mortality_raw_data.merge(population) normed_columns_of_interest = &#39;Norm. &#39; + column_of_interest mortality_raw_data[normed_columns_of_interest] = mortality_raw_data[column_of_interest]/ mortality_raw_data[&#39;population&#39;] . . #collapse _ = mortality_raw_data.plot(&quot;Date&quot;,normed_columns_of_interest , figsize = (12,6)) . . נראה שיש מגמת ירידה בתמותה המנורמלת לפי שנים, אך היא נראית חלשה יותר מאשר המגמה בנתונים הגולמיים. . #collapse _ = mortality_raw_data.boxplot(column = normed_columns_of_interest, by=&#39;month&#39;, figsize = (12,6)) . . יש עונתיות שנתית ברורה בתמותה. כמו כן, יש תנודתיות רבה בין השנים. התנודתיות גדולה יותר בחורף. רואים את זה גם בנתונים הגולמיים וגם ובמתוקננים. . &#1502;&#1493;&#1491;&#1500; &#1500;&#1502;&quot;&#1505; . נתחיל מניתוח דמוי למ&quot;ס. נשווה את התחלואה בפועל (פר שבוע) לממוצע של חמש השנים האחרונות. ליתר דיוק ניקח ממוצע של הנתונים המתוקננים ונכפיל באוכלוסיה העכשווית. כמו כן, עקב רעש די גדול ניקח ממוצע נע של 3 שבועות על ה&quot;מודל&quot;. נחשב גבולות בטחון על פי סטיית תקן * 1.96 (z-score מתאים לרווח סמך של 95%) . #collapse class CBSModel(): def __init__(self, metric, norm_factor = population[&#39;population&#39;].values[-1]): self._metric = metric self._norm_factor = norm_factor def fit(self, df): mean = self._norm_factor * df .query(&#39;2015 &lt;= year &lt;= 2019&#39;) .groupby(&#39;Week&#39;)[self._metric].mean() mean = mean.rolling(3, center=True, min_periods=1).mean() std = self._norm_factor * df .query(&#39;2015 &lt;= year &lt;= 2019&#39;) .groupby(&#39;Week&#39;)[self._metric].std() std = std.rolling(3, center=True, min_periods=1).mean() self._model = pd.concat([mean, std], axis = 1) self._model.columns = [&#39;mean&#39;, &#39;std&#39;] def predict(self, df, conf_level = 1.96): return df.merge(self._model, left_on=&#39;Week&#39;, right_index=True). assign( actual_mortality = lambda x: x[self._metric] * self._norm_factor, predicted_mortality = lambda x: x[&#39;mean&#39;], upper_bound = lambda x: x[&#39;mean&#39;] + (conf_level * x[&#39;std&#39;]), lower_bound = lambda x: x[&#39;mean&#39;] - (conf_level * x[&#39;std&#39;]), )[[&#39;Date&#39;, &#39;year&#39;, &#39;Week&#39;, &#39;month&#39;, &#39;actual_mortality&#39;, &#39;predicted_mortality&#39; ,&#39;lower_bound&#39;, &#39;upper_bound&#39;]] . . #collapse cbs_model = CBSModel(normed_columns_of_interest) pre_covid_data = mortality_raw_data.query(&#39;Date &lt;= &quot;2020-03-01&quot;&#39;) cbs_model.fit(pre_covid_data) cbs_result = cbs_model.predict(mortality_raw_data.query(&#39;Date &gt;= &quot;2020-01-01&quot;&#39;)) . . #collapse def plot_mortality_predition(result): fig = plt.figure(figsize = (12,6)) plt.plot(result[&#39;Date&#39;], result[&#39;actual_mortality&#39;],&#39;r&#39;, label = &#39;Actual mortality&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;predicted_mortality&#39;],&#39;b&#39;, label = &#39;Predicted mortality&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;upper_bound&#39;],&#39;b--&#39;) plt.plot(result[&#39;Date&#39;], result[&#39;lower_bound&#39;],&#39;b--&#39;) _=plt.legend() . . #collapse plot_mortality_predition(cbs_result) . . בחודשי החורף (ינואר ופברואר) תמותה בחסר, כפי שצויין גם בדו&quot;ח הלמ&quot;ס, כנראה עקב שפעת יחסית קלה השנה. ניתן לראות שהחל מתחילת יולי התחלואה מעל למצופה בכל השבועות. אולם רק בשבועיים העלייה היא מעל לגבול העליון של ה-95%. אחד מהם כבר היה בדו&quot;ח הלמ&quot;ס המקורי ואחד &quot;חדש&quot; מאוגוסט. נסתכל גם על ממוצע נע של התמותה בפועל להחלקת רעשים: . #collapse mortality_raw_data[&#39;Mortality. mavg&#39;] = mortality_raw_data[normed_columns_of_interest] .rolling(3, center=True, min_periods=1).mean() cbs_model2 = CBSModel(&#39;Mortality. mavg&#39;) pre_covid_data = mortality_raw_data.query(&#39;Date &lt;= &quot;2020-03-01&quot;&#39;) cbs_model2.fit(pre_covid_data) cbs_result2 = cbs_model2.predict(mortality_raw_data.query(&#39;year == 2020&#39;)) plot_mortality_predition(cbs_result2) . . כאן ניתן לראות שאנחנו כבר כמה שבועות טובים רצופים מעל הגבול העליון. מהי ההערכה לתמותה עודפת מצטברת? נסתכל לפי חודשים: . #collapse cbs_result.assign( excess_mortality = lambda x: x.actual_mortality - x.predicted_mortality, excess_mortality_percent = lambda x: (x.actual_mortality - x.predicted_mortality)/x.predicted_mortality ).groupby(&#39;month&#39;) .agg({&#39;excess_mortality&#39;: &#39;sum&#39;, &#39;excess_mortality_percent&#39;: &#39;mean&#39;}) . . excess_mortality excess_mortality_percent . month . 1 -274.799115 | -0.062750 | . 2 -369.688408 | -0.088203 | . 3 100.541240 | 0.023214 | . 4 32.815022 | 0.009317 | . 5 146.766899 | 0.043999 | . 6 -71.662591 | -0.017923 | . 7 174.894336 | 0.053895 | . 8 166.480374 | 0.068382 | . אם כן, אנו רואים תמותה כי בחודש יולי יש תמותה עודפת של כ-175 מתים. גם באוגוסט יש תמותה עודפת לא מובוטלת. אם ניקח בחשבון כי נתוני אוגוסט הם חלקיים (3 שבועות?), אזי במונחים חודשיים מדובר בכ-250 מתים עודפים וסה&quot;כ בכ-425 בחודשי הקיץ יולי אוגוסט. באחוזים מדובר בקרוב ל7% על חודש אוגוסט. אם נמשיך בקצב זה (שעשוי אף לעשות לצערנו) על תמותה שנתית של כ-45000 נגיע לתמותה עודפת של כ3100 איש. . אז מה הלאה? חישוב ממוצעים וסטיית תקן זה טוב ויפה אבל זה סה&quot;כ סטטיסיטיקה. כData scientists שמכבדים את עצמם לא צריך להשתמש במודל Machine Learning יותר רציני. וכאומרים Machine learning כמובן שמדובר על Deep learning אך כיוון שקצרה היריעה, נתחיל מלנסות prophet כמודל time series לחזות התמותה במקום ממוצע. אבל דבר ראשון נפסיק עם העברית שלא מרונדרת טוב ונתחיל לכתוב באנגלית. . Prophet . Let&#39;s now use prophet to estimate the expected mortality. Using prophet has several benefits. It&#39;s easy to run out of the box. In addition, it&#39;s supposed to take into account seasonality and also has built in mechanism to estimate the trend. Therefore in we&#39;ll work with the raw data without normalizing by population. . #collapse from fbprophet import Prophet prophet_df = mortality_raw_data[[&quot;Date&quot;,column_of_interest]].copy().rename(columns = {&#39;Date&#39;:&#39;ds&#39;, column_of_interest:&quot;y&quot;}) pre_corona_data = prophet_df.query(&#39;ds &lt; &quot;2020-03-01&quot;&#39;) . . #collapse #hide_output prophet = Prophet() prophet.fit(pre_corona_data) forecast = prophet.predict(prophet_df) forecast = forecast.merge(prophet_df) . . INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this. . prophet.plot(forecast, xlabel=&#39;Date&#39;, ylabel=&#39;Mortality&#39;, figsize = (12,6)); . Looks like prophet captures reasonably well the time series, trend and seasonality. The large noise during some of the winter periods is evident. . #collapse forecast = forecast.rename(columns = { &#39;y&#39;:&#39;actual_mortality&#39;, &#39;yhat&#39;:&#39;predicted_mortality&#39; ,&#39;yhat_lower&#39;:&#39;lower_bound&#39;, &#39;yhat_upper&#39;:&#39;upper_bound&#39;, &#39;ds&#39;:&#39;Date&#39; }) plot_mortality_predition(forecast.query(&#39;Date &gt;= &quot;2020-01-01&quot;&#39;)) . . In general this seems very similar to the &quot;CBS&quot; model. Mortality is above expectation since the beginning of July and above the upper confidence bound in two weeks. It&#39;s important to note that it&#39;s seems it is not especially rare to get several consecutive weeks above the upper confidence bound in the winter seasons. . So, I would say that from the data shows that covid isn&#39;t a &quot;light flu&quot;, maybe a &quot;flu with public relations&quot; but not a light one. Let&#39;s hope it stays this way and mortality doesn&#39;t increase, though it doesn&#39;t looks promising right now :( . Absolute excess mortality by month using prophet: . #collapse forecast[&#39;month&#39;] = forecast[&#39;Date&#39;].apply(lambda x: x.month) forecast.query(&#39;Date &gt;= &quot;2020-01-01&quot;&#39;).assign( excess_mortality = lambda x: x.actual_mortality - x.predicted_mortality, excess_mortality_percent = lambda x: (x.actual_mortality - x.predicted_mortality)/x.predicted_mortality ).groupby(&#39;month&#39;) .agg({&#39;excess_mortality&#39;: &#39;sum&#39;, &#39;excess_mortality_percent&#39;: &#39;mean&#39;}) . . excess_mortality excess_mortality_percent . month . 1 -60.353954 | -0.014609 | . 2 -238.216539 | -0.058986 | . 3 117.046212 | 0.026363 | . 4 55.252951 | 0.015853 | . 5 186.623639 | 0.056669 | . 6 -84.244496 | -0.021004 | . 7 178.530829 | 0.055102 | . 8 140.197227 | 0.056965 | . Very similar number to the CBS model. Somewhat higher numbers for July and somewhat lower number for August. . That&#39;s it for now. I might try a deep learning model at some point, but frankly I doubt it will make a real difference. If you think otherwise please let me know .",
            "url": "https://adiell.github.io/fp-blog/covid-19/2020/09/20/Israel_excess_mortality.html",
            "relUrl": "/covid-19/2020/09/20/Israel_excess_mortality.html",
            "date": " • Sep 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hello :) . My name is Adiel Loinger. I have a Ph.D in physics from the Hebrew University. Working as a Data scientist to make a living. .",
          "url": "https://adiell.github.io/fp-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}